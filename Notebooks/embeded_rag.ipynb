{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    base_url=\"https://models.inference.ai.azure.com\",\n",
    "    api_key=os.getenv('GITHUB_TOKEN'),\n",
    ")\n",
    "\n",
    "if client:\n",
    "    print(\"Sėkmingai prisijungta Prie Github modelių.\\n\\n\")\n",
    "else:\n",
    "    print(\"Prisijungti prie Github modelių nepavyko.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"write me haiku about coding.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    # temperature=1,\n",
    "    max_tokens=4096,\n",
    "    # top_p=1\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "print('\\n pirmos užklausos pabaiga \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V.I.I.S\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: tensor([[ 4.0734e-01,  2.8004e-01,  2.1713e-02,  5.1135e-01,  3.4228e-02,\n",
      "         -8.6229e-02, -8.1606e-02, -7.3586e-02,  1.9557e-01,  1.6150e-01,\n",
      "          5.0413e-01, -2.2729e-01,  3.3268e-02,  1.9821e-01,  9.0419e-02,\n",
      "         -2.0050e-01,  1.1427e-01, -2.7303e-01, -1.6283e-01,  2.4640e-01,\n",
      "          3.3489e-01,  2.6473e-01, -4.7299e-02,  1.1451e-01,  9.6627e-02,\n",
      "          4.6956e-02, -2.8461e-01,  3.5311e-02,  2.2724e-01, -2.1794e-02,\n",
      "         -2.6963e-01, -2.0099e-02,  3.1292e-01,  2.3231e-01,  8.2247e-02,\n",
      "         -1.5383e-02,  2.7738e-01,  1.7025e-01, -2.8432e-02,  7.1675e-02,\n",
      "          5.5939e-02, -5.1937e-01,  9.2315e-02,  1.0672e-01,  5.2500e-02,\n",
      "          1.8275e-02, -1.5434e-01,  5.1839e-02, -2.3399e-02, -1.3693e-01,\n",
      "         -2.5404e-01, -3.4109e-01, -2.7812e-01, -6.5877e-02,  2.7457e-02,\n",
      "          1.1150e-01,  1.7250e-01,  7.2475e-02,  2.4037e-01,  2.0599e-01,\n",
      "         -1.6714e-01, -1.1771e-01, -3.4561e-01,  4.0167e-01,  7.1960e-01,\n",
      "          2.6102e-01, -1.9975e-01, -4.3441e-01, -2.1515e-01,  7.1222e-02,\n",
      "          1.0781e-01,  9.4583e-02,  2.1085e-01,  4.7414e-02, -1.8398e-02,\n",
      "         -7.2448e-02, -3.3786e-03, -5.4530e-01,  5.9843e-01,  2.6847e-01,\n",
      "         -4.2963e-01, -3.8102e-01, -8.1631e-02,  2.2217e-01, -4.2170e-02,\n",
      "         -2.8094e-01,  3.7010e-01, -1.6585e-01, -3.8291e-01,  1.0518e-01,\n",
      "         -1.6550e-01, -1.2780e-01,  2.5601e-02,  2.1877e-02, -2.4653e-01,\n",
      "         -8.0148e-02, -4.0129e-01, -1.1458e-02, -5.3798e-03,  2.0807e-01,\n",
      "          2.1155e-02,  1.2322e-01,  3.6091e-02,  3.0525e-01, -4.7384e-01,\n",
      "         -4.2490e-01,  1.7067e-03, -2.7867e-01,  9.9723e-02, -3.7378e-02,\n",
      "         -1.4809e-01, -1.0143e-02,  2.8780e-01,  9.4613e-02, -6.0269e-02,\n",
      "          4.6911e-02, -5.9522e-01,  1.2559e-01, -7.6236e-02,  2.3888e-01,\n",
      "          2.9738e-01,  3.7837e-01, -1.4347e-01, -6.3719e-02, -3.0129e-01,\n",
      "         -3.8987e-01,  2.6560e-01, -3.3644e-32, -1.2487e-01, -3.2269e-01,\n",
      "          2.1027e-01,  3.5758e-01,  4.9575e-02, -1.1816e-01, -1.0268e-01,\n",
      "          3.3049e-01, -1.1078e-01, -3.8261e-04, -1.2478e-02, -4.5850e-01,\n",
      "          6.4321e-02,  1.9633e-01,  4.1374e-01,  4.7443e-01, -3.7054e-01,\n",
      "          3.3599e-01, -2.2589e-01,  2.6835e-01, -1.7067e-01,  1.8421e-01,\n",
      "         -8.9235e-02, -3.1636e-01, -4.4110e-01, -5.4079e-01,  1.0670e-02,\n",
      "          4.0655e-02, -2.2743e-01,  9.8368e-02,  5.1490e-02,  1.2614e-01,\n",
      "         -1.2941e-01,  2.9051e-01,  9.7985e-02,  8.0674e-02,  1.7052e-01,\n",
      "         -3.7775e-01, -1.2485e-01,  4.9528e-02, -2.9706e-01, -1.3760e-01,\n",
      "         -4.9655e-02,  6.1243e-02,  4.6133e-01, -5.8682e-02, -6.8839e-02,\n",
      "         -1.2657e-01, -3.0440e-02,  1.0726e-01, -1.2604e-01,  2.1234e-01,\n",
      "          3.5587e-01, -1.6134e-01,  1.5549e-01,  3.1249e-01,  2.3832e-01,\n",
      "         -5.0893e-02, -1.6781e-01,  3.1752e-01, -1.3155e-01,  2.9165e-01,\n",
      "         -2.9007e-01,  2.7191e-01,  3.2902e-02,  9.0413e-02, -2.0735e-01,\n",
      "         -1.9792e-01,  2.5607e-01,  1.5992e-01, -7.5124e-02, -3.5268e-01,\n",
      "         -2.4590e-01,  3.0496e-01, -6.2709e-02, -3.4211e-01,  7.1857e-02,\n",
      "          1.6553e-01,  4.0083e-02,  4.7311e-02,  1.1315e-01, -5.4173e-01,\n",
      "          1.3644e-01, -2.5507e-01, -4.5338e-01, -2.7146e-03, -9.3340e-02,\n",
      "         -4.2795e-01,  1.1818e-01, -1.1991e-01,  6.2690e-02,  1.1215e-01,\n",
      "          1.8958e-01, -1.6300e-01,  1.0687e-01,  1.3999e-32, -1.6553e-01,\n",
      "          3.1674e-01, -3.4683e-01,  4.1818e-01,  4.2118e-01, -1.4565e-01,\n",
      "          3.1814e-01, -1.6144e-01, -1.8116e-01,  6.5185e-01, -2.1795e-01,\n",
      "          1.5956e-01, -2.0490e-02, -1.0674e-01,  1.9023e-01,  5.4536e-02,\n",
      "          5.2267e-02, -2.3691e-01, -8.8359e-02, -1.1557e-01, -2.8331e-01,\n",
      "          6.1096e-01,  8.2526e-02,  4.9160e-01, -2.0134e-01,  1.8061e-02,\n",
      "          6.9105e-02, -3.2749e-01, -3.5804e-01,  9.7834e-02,  1.0218e-01,\n",
      "         -1.6348e-01, -4.8252e-01, -4.0939e-02,  5.1845e-02,  4.1998e-02,\n",
      "          4.9485e-01, -3.6934e-01, -2.5011e-01,  1.4967e-01,  1.9898e-02,\n",
      "          1.3274e-01,  3.2246e-01,  6.9341e-01,  6.5729e-02,  5.8184e-02,\n",
      "         -1.1816e-01, -6.8093e-01, -2.0934e-01,  2.0815e-01, -2.6862e-01,\n",
      "          1.1594e-01, -6.1318e-02,  8.3776e-02, -3.2748e-01,  5.4883e-02,\n",
      "         -1.5405e-01, -1.4323e-01, -1.2109e-01, -1.0956e-02, -4.7175e-01,\n",
      "          2.9162e-01,  3.3060e-02,  1.5533e-01,  1.1089e-01, -3.4483e-01,\n",
      "         -3.7302e-01,  4.6070e-01,  1.2828e-01, -2.9150e-01,  4.9728e-01,\n",
      "          1.4299e-01, -5.2614e-01, -1.1987e-01, -1.6059e-01, -3.9795e-01,\n",
      "         -3.9514e-01, -8.5251e-02, -9.3327e-02, -4.0098e-01, -8.7251e-02,\n",
      "         -2.5746e-01,  2.2709e-02,  7.3730e-02, -3.9358e-01,  1.8619e-01,\n",
      "         -2.1387e-02, -1.3516e-01, -4.9306e-02,  2.1358e-01, -8.1828e-02,\n",
      "         -2.6641e-01,  1.9203e-01, -1.1137e-01, -1.2972e-01, -9.4617e-08,\n",
      "         -9.0226e-02, -5.6590e-02,  7.0782e-02,  3.2176e-02,  3.5620e-03,\n",
      "          3.0241e-01,  3.2746e-01, -2.8776e-02, -1.4748e-01, -3.9620e-03,\n",
      "          3.1069e-01,  3.2094e-01, -4.7332e-01, -4.1489e-05,  2.9150e-01,\n",
      "         -1.3241e-01,  1.1719e-01, -1.0272e-01, -1.2900e-02,  4.0734e-01,\n",
      "         -2.3423e-01,  2.3075e-01,  6.3741e-02,  2.2463e-01, -1.4396e-02,\n",
      "          2.1337e-01,  4.8123e-01,  3.1058e-01,  1.6240e-02,  2.1733e-01,\n",
      "          5.3276e-01,  3.1055e-01, -1.7790e-01, -1.5245e-01, -7.1355e-02,\n",
      "          3.9752e-01,  2.7406e-01, -3.1384e-01,  1.1153e-01,  9.2946e-02,\n",
      "         -2.4907e-01,  3.4902e-01, -6.9545e-02,  3.7779e-01, -5.3940e-02,\n",
      "         -2.3952e-01, -1.5265e-01, -1.4278e-01, -7.3281e-02, -2.6058e-01,\n",
      "         -4.2810e-02,  1.0179e-01,  2.1758e-01, -1.1057e-01,  1.2956e-01,\n",
      "         -1.5978e-01, -1.6889e-02, -1.4697e-01, -3.4582e-01,  1.1257e-01,\n",
      "          4.3378e-01,  2.2088e-02,  3.9566e-01, -4.7861e-01]],\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained Hugging Face model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Input text\n",
    "text = \"This is a test sentence.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Take the mean pooling of the model output to create embeddings\n",
    "embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "print(\"Embeddings:\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 403: {\"error\":\"Your auth method doesn't allow you to make inference requests\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "hf_token = os.getenv('HF_API_TOKEN')\n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# headers = {\"Authorization\": f\"Bearer hf_token\"}\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\"\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {hf_token}\"}\n",
    "\n",
    "payload = {\n",
    "    \"query_embedding\": embeddings,  # Pass the embedding vector here\n",
    "    \"filter\": {\"category\": \"science\"},  # Other filters or metadata\n",
    "    \"top_k\": 5  # Number of nearest neighbors to retrieve\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "# Convert tensor to list before sending\n",
    "payload[\"query_embedding\"] = embeddings.detach().numpy().tolist()\n",
    "response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "# Parse embeddings from the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response)\n",
    "else:\n",
    "    print(f\"Error {response.status_code}:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key\n",
    "openai_key = os.getenv('OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from rich import print\n",
    "\n",
    "def generate_embedding(text, model=\"text-embedding-3-small\", api_key=openai_key):\n",
    "    \"\"\"Generate embeddings for a given text using OpenAI's API.\"\"\"\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    response = client.embeddings.create(input=text, model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "print(generate_embedding(\"Hello, world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")\n",
    "print(docs[0].page_content[:500] + \"........\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
